# src/llm/openai_client.py

import os
import logging
from typing import Dict, Any, Optional
import openai

# Temel loglama ayarlarÄ±
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

class OpenAIClient:
    """
    OpenAI API'si ile iletiÅŸimi yÃ¶neten basit bir istemci.
    """
    def __init__(self, config: Dict[str, Any]):
        self.logger = logging.getLogger("OpenAIClient")

        self.model_capabilities = {
            "gpt-4o": {"vision": True},
            "gpt-4o-mini": {"vision": False}, # Daha kÃ¼Ã§Ã¼k, gÃ¶rsel desteklemeyen model
            "gpt-3.5-turbo": {"vision": False}
        }
        
        # API anahtarÄ±nÄ± ortam deÄŸiÅŸkenlerinden (environment variable) oku
        api_key_env = config.get('api_key_env', 'OPENAI_API_KEY')
        api_key = os.getenv(api_key_env)
        
        if not api_key:
            self.logger.error(f"ğŸ”´ '{api_key_env}' ortam deÄŸiÅŸkeni bulunamadÄ±. LÃ¼tfen API anahtarÄ±nÄ±zÄ± ayarlayÄ±n.")
            raise ValueError("OpenAI API anahtarÄ± ayarlanmamÄ±ÅŸ.")
            
        # OpenAI istemcisini baÅŸlat
        self.client = openai.OpenAI(api_key=api_key)
        
        # Model ve diÄŸer ayarlarÄ± config'den al
        self.model = config.get('model', 'gpt-4o')
        self.temperature = config.get('temperature', 0.7)
        self.max_tokens = config.get('max_tokens', 2000)
        
        self.logger.info(f"OpenAI istemcisi '{self.model}' modeli ile baÅŸlatÄ±ldÄ±.")

    def has_vision_capability(self) -> bool:
        """Checks if the currently configured model supports vision."""
        # Modeli yetenek haritasÄ±nda ara, bulamazsan gÃ¼venli olmasÄ± iÃ§in False dÃ¶ndÃ¼r.
        return self.model_capabilities.get(self.model, {}).get("vision", False)

    def get_completion(self, system_prompt: str, user_prompt: str, image_base64: Optional[str] = None) -> str:
        """
        Verilen prompt'lar ile OpenAI'den bir cevap Ã¼retir.
        """
        self.logger.info("OpenAI'den cevap isteniyor...")
        if image_base64:
            self.logger.info("   - Request includes an image.")

        user_content = [
            {
                "type": "text",
                "text": user_prompt
            }
        ]

        # If an image is provided, add it to the content list.
        if image_base64:
            user_content.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/png;base64,{image_base64}"
                }
            })
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    # The 'content' is now the list we constructed.
                    {"role": "user", "content": user_content}
                ],
                temperature=self.temperature,
                max_tokens=self.max_tokens,
            )
            content = response.choices[0].message.content
            self.logger.info("Successfully received completion.")
            return content.strip() if content else ""
        except Exception as e:
            self.logger.error(f"OpenAI API Ã§aÄŸrÄ±sÄ± sÄ±rasÄ±nda bir hata oluÅŸtu: {e}")
            return "ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu ve ÅŸu anda cevap veremiyorum."